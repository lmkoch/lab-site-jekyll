<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> research | machine learning in medicine lab </title> <meta name="author" content="MLM Lab"> <meta name="description" content="Our research interests."> <meta name="keywords" content="mlm-lab, AI, trustworthy AI, medicine, health, diabetes"> <link rel="stylesheet" href="/lab-site-jekyll/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/lab-site-jekyll/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/lab-site-jekyll/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/lab-site-jekyll/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lmkoch.github.io/lab-site-jekyll/research/"> <script src="/lab-site-jekyll/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/lab-site-jekyll/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/lab-site-jekyll//"> machine learning in medicine lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/lab-site-jekyll/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/lab-site-jekyll/research/">research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/lab-site-jekyll/people/">people </a> </li> <li class="nav-item "> <a class="nav-link" href="/lab-site-jekyll/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/lab-site-jekyll/jobs/">join us </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">research</h1> <p class="post-description">Our research interests.</p> </header> <article> <p>Methodological interests in trustworthy AI:</p> <ul> <li>Interpretable machine learning</li> <li>Performance generalisation and performance prediction</li> <li>Disentangled representation learning</li> </ul> <p>Application areas:</p> <ul> <li>Interpretation of Continuous Glucose Monitoring (CGM) data, including for example CGM forecasting and risk factor prediction</li> <li>Medical image analysis including for example image classification, segmentation, disease progression modelling</li> </ul> <p>Check out some example projects (past and ongoing) below. For a comprehensive list of publications, check out <a href="https://scholar.google.com/citations?user=R0iwuiIAAAAJ" rel="external nofollow noopener" target="_blank">google scholar</a>.</p> <h3 id="timeseries-transformers-for-analysing-continuous-glucose-monitoring-data">Timeseries transformers for analysing continuous glucose monitoring data</h3> <p>More than 530 million people globally suffer from diabetes, a leading cause of death and contributor to a host of long-term serious health complications. To treat diabetes, individuals need to manage their blood glucose level through diet, exercise, weight loss and medications. Many people with diabetes, in particular with Type I diabetes, require frequent insulin injections throughout the day to maintain a healthy glucose profile.</p> <p>Frequently measuring glucose, for example through continuous glucose monitoring (CGM) devices, is therefore a crucial component of diabetes care. CGMs are small wearable devices widely used by people with diabetes to continuously monitor their blood glucose levels. They provide valuable information that help patients make informed decisions about their diet and insulin dosing. However, control of blood sugar levels remains challenging, as a myriad of complex factors influence the dynamics of a patient’s glucose profile, including cardiometabolic risk factors such as obesity, age, sex, or exercise. These complex relationships are not yet fully understood, but they will need to be incorporated for effective next generation treatment systems.</p> <p>Our research interests include:</p> <ul> <li>Transformer-based approaches for training large CGM models</li> <li>Glucose forecasting</li> <li>Cardiometabolic risk factor prediction and biomarker discovery</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/lab-site-jekyll/assets/img/research/cgm-480.webp 480w,/lab-site-jekyll/assets/img/research/cgm-800.webp 800w,/lab-site-jekyll/assets/img/research/cgm-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/lab-site-jekyll/assets/img/research/cgm" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Research area: analysing CGM data" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="interpretable-methods-for-diabetic-retinopathy-detection">Interpretable methods for diabetic retinopathy detection</h3> <p>Deep learning models typically lack interpretability, thereby posing ethical concerns and preventing wide adoption in clinical practice. Interpreting deep learning models typically relies on post-hoc saliency map techniques. However, these techniques often fail to serve as actionable feedback to clinicians, and they do not directly explain the decision mechanism. In our research, we are interested in two approaches to mitigate the shortcomings saliency maps:</p> <ol> <li> <p>Inherently interpretable models, which combine the feature extraction capabilities of deep neural networks with advantages of sparse linear models in interpretability.</p> </li> <li> <p>Visual counterfactual explanations, which provide realistic counterfactuals (“what would this image have looked like, were the patient healthy?”) to illustrate a ML model’s internal reasoning.</p> </li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/lab-site-jekyll/assets/img/research/kerol_bagnets-480.webp 480w,/lab-site-jekyll/assets/img/research/kerol_bagnets-800.webp 800w,/lab-site-jekyll/assets/img/research/kerol_bagnets-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/lab-site-jekyll/assets/img/research/kerol_bagnets" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Research area: interpretable ML" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Relevant publications:</p> <ul> <li><span id="djoumessi2023sparse">Djoumessi, K. R. D., Ilanchezian, I., Kühlewein, L., Faber, H., Baumgartner, C. F., Bah, B., Berens, P., &amp; Koch, L. M. (2023). Sparse Activations for Interpretable Disease Grading. <i>Proceedings of Machine Learning Research</i>, <i>6</i>, 1–17.</span></li> <li><span id="sun2023right">Sun, S., Koch, L. M., &amp; Baumgartner, C. F. (2023). Right for the Wrong Reason: Can Interpretable ML Techniques Detect Spurious Correlations? <i>Proc. International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</i>, <i>14221 LNCS</i>, 425–434. https://doi.org/10.1007/978-3-031-43895-0</span></li> <li><span id="sun2023inherently">Sun, S., Woerner, S., Maier, A., Koch, L. M., &amp; Baumgartner, C. F. (2023). Inherently Interpretable Multi-Label Classification Using Class-Specific Counterfactuals. <i>Proceedings of Machine Learning Research</i>, <i>227</i>.</span></li> <li><span id="boreiko2022visual">Boreiko, V., Ilanchezian, I., Ayhan, M. S., Müller, S., Koch, L. M., Faber, H., Berens, P., &amp; Hein, M. (2022). Visual Explanations for the Detection of Diabetic Retinopathy from Retinal Fundus Images. <i>Proc. International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</i>, <i>13432 LNCS</i>, 539–549. https://doi.org/10.1007/978-3-031-16434-7</span></li> </ul> <h3 id="distribution-shift-detection-for-postmarket-surveillance-of-medical-ai-algorithms">Distribution shift detection for postmarket surveillance of medical AI algorithms</h3> <p>Distribution shifts remain a problem for the safe application of regulated medical AI systems, and may impact their real-world performance if undetected. Postmarket shifts can occur for example if algorithms developed on data from various acquisition settings and a heterogeneous population are predominantly applied in hospitals with lower quality data acquisition or other centre-specific acquisition factors, or where some ethnicities are over-represented. Therefore, distribution shift detection could be important for monitoring AI-based medical products during postmarket surveillance. We investigated, implemented and evaluated various deep-learning based shift detection techniques on simulated shifts in medical imaging datasets. We then simulated population shifts and data acquisition shifts and analysed the performance of the shift detectors at detecting both subgroup and out-of-distribution shifts.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/lab-site-jekyll/assets/img/research/lisa_subgroups-480.webp 480w,/lab-site-jekyll/assets/img/research/lisa_subgroups-800.webp 800w,/lab-site-jekyll/assets/img/research/lisa_subgroups-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/lab-site-jekyll/assets/img/research/lisa_subgroups" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Research area: distribution shift detection" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li><span id="koch2024postmarket">Koch, L. M., Baumgartner, C. F., &amp; Berens, P. (2024). Distribution Shift Detection for the Postmarket Surveillance of Medical AI Algorithms: A Retrospective Simulation Study. <i>Npj Digital Medicine</i>. https://doi.org/https://doi.org/10.1038/s41746-024-01085-w</span></li> <li><span id="koch2022hidden">Koch, L. M., Schürch, C. M., Gretton, A., &amp; Berens, P. (2022). Hidden in Plain Sight: Subgroup Shifts Escape OOD Detection. <i>Proceedings of Machine Learning Research</i>, <i>172</i>, 726–740.</span></li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 MLM Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/lab-site-jekyll/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/lab-site-jekyll/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/lab-site-jekyll/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/lab-site-jekyll/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/lab-site-jekyll/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/lab-site-jekyll/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/lab-site-jekyll/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>